{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d63a910-5903-4787-b668-d772a77422bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# code for enabling this notebook to work within cursor\n",
    "coralme_dir = '/home/chris/zuniga/coralme/' #'../'\n",
    "sys.path.insert(0, coralme_dir)\n",
    "\n",
    "import subprocess\n",
    "from cobra.io import load_json_model, write_sbml_model\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def extract_json_from_window_data(html):\n",
    "    start = html.find(\"window.data =\")\n",
    "    if start == -1:\n",
    "        raise ValueError(\"Could not find 'window.data =' in the HTML.\")\n",
    "\n",
    "    start += len(\"window.data =\")\n",
    "    i = start\n",
    "    brace_count = 0\n",
    "    in_string = False\n",
    "    escape = False\n",
    "\n",
    "    # Skip whitespace to find the first {\n",
    "    while html[i] in \" \\n\\r\\t\":\n",
    "        i += 1\n",
    "\n",
    "    if html[i] != '{':\n",
    "        raise ValueError(\"Expected '{' after 'window.data ='\")\n",
    "\n",
    "    json_start = i\n",
    "    brace_count += 1\n",
    "    i += 1\n",
    "\n",
    "    # Parse until all braces are closed\n",
    "    while i < len(html):\n",
    "        char = html[i]\n",
    "\n",
    "        if in_string:\n",
    "            if escape:\n",
    "                escape = False\n",
    "            elif char == '\\\\':\n",
    "                escape = True\n",
    "            elif char == '\"':\n",
    "                in_string = False\n",
    "        else:\n",
    "            if char == '\"':\n",
    "                in_string = True\n",
    "            elif char == '{':\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0:\n",
    "                    return html[json_start:i + 1]\n",
    "        i += 1\n",
    "\n",
    "    raise ValueError(\"Could not parse full JSON object from 'window.data ='\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd564df-f400-4fa1-b11d-d0678db3ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run memote on each, saving to json\n",
    "base_dir = os.path.join(coralme_dir, 'species_files', 'Pseudomonas_files')\n",
    "output_dfs = []\n",
    "for f in os.listdir(os.path.join(base_dir, 'individual_species')):\n",
    "    if 'Reference' in f: continue\n",
    "    \n",
    "    # look to see if memote solution already exists\n",
    "    M_json_path = os.path.join(base_dir, 'individual_species', f, 'inputs', 'model.json')\n",
    "    M_xml_path = os.path.join(base_dir, 'individual_species', f, 'inputs', 'model.xml')\n",
    "    report_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'memote_report.html')\n",
    "    if os.path.exists(M_json_path) and not os.path.exists(M_xml_path):\n",
    "        model = load_json_model(M_json_path)\n",
    "        write_sbml_model(model, M_xml_path)\n",
    "\n",
    "    # run memote\n",
    "    if not os.path.exists(report_path):\n",
    "        print(f+' running memote...')\n",
    "        result = subprocess.run(['memote', 'report', 'snapshot', '--filename', report_path, M_xml_path], capture_output=True, text=True)\n",
    "\n",
    "    # Load and extract results\n",
    "    with open(report_path, encoding=\"utf-8\") as file:\n",
    "        html = file.read()\n",
    "    \n",
    "    json_str = extract_json_from_window_data(html)\n",
    "    data = json.loads(json_str)\n",
    "    \n",
    "    # Summarize tests\n",
    "    test_names = []\n",
    "    test_results = []\n",
    "    test_metrics = []\n",
    "    \n",
    "    # Loop through all tests in the memote data\n",
    "    for test_id, test in data.get(\"tests\", {}).items():\n",
    "        name = test.get(\"title\", test_id)\n",
    "        result = test.get(\"result\", None)\n",
    "        metric = test.get(\"metric\", None)\n",
    "    \n",
    "        # Normalize result (handle dicts like per-database results)\n",
    "        if isinstance(result, dict):\n",
    "            result = None\n",
    "    \n",
    "        # Normalize metric\n",
    "        if not isinstance(metric, (int, float)):\n",
    "            metric = None\n",
    "    \n",
    "        # Append to lists\n",
    "        test_names.append(name)\n",
    "        test_results.append(result)\n",
    "        test_metrics.append(metric)\n",
    "    \n",
    "    # Optionally print the first few entries to verify\n",
    "    output_df = pd.DataFrame(index = test_names)\n",
    "    output_df[f+'_result'] = test_results\n",
    "    output_df[f+'_metric'] = test_metrics\n",
    "    output_dfs.append(output_df)\n",
    "\n",
    "# TODO - concatenate all these output dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fce52-130b-4d1a-abfb-54ee32cfb5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
