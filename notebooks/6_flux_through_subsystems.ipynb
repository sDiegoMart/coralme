{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97837b83-494e-4645-8056-09b5750e1c9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/site-packages/pandas/compat/_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xlrd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m     files\u001b[38;5;241m.\u001b[39mappend(path)\n\u001b[1;32m     70\u001b[0m files\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m---> 71\u001b[0m models_source_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m models_source_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miML1515\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/site-packages/pandas/io/excel/_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/site-packages/pandas/io/excel/_base.py:1695\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/site-packages/pandas/io/excel/_xlrd.py:34\u001b[0m, in \u001b[0;36mXlrdReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03mReader using xlrd engine.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m{storage_options}\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall xlrd >= 1.0.0 for Excel support\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxlrd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[0;32m~/miniforge3/envs/coralme/lib/python3.10/site-packages/pandas/compat/_optional.py:144\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "# settings\n",
    "force_rerun = False\n",
    "run_once = False # useful for debugging, just runs one sample\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# code for enabling this notebook to work within cursor\n",
    "coralme_dir = '/home/chris/zuniga/coralme/' #'../'\n",
    "sys.path.insert(0, coralme_dir)\n",
    "\n",
    "#import cobra\n",
    "import coralme\n",
    "import coralme.solver.solver\n",
    "import coralme.builder.main\n",
    "import coralme.core.model\n",
    "import pickle\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "from adjustText import adjust_text\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def get_n_colors_from_colormap(n, colormap_name='viridis'):\n",
    "    cmap = cm.get_cmap(colormap_name)\n",
    "    if n == 1:\n",
    "        return(cmap(1))\n",
    "    else:\n",
    "        return [cmap(i / (n - 1)) for i in range(n)]\n",
    "    \n",
    "def create_m_to_me_mapping(m_model, me_model):\n",
    "    \"\"\"\n",
    "    Create a dictionary mapping M model reaction IDs to their corresponding ME model reaction IDs\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    m_model : cobra.Model\n",
    "        Original M model\n",
    "    me_model : coralme.core.MEModel\n",
    "        ME model generated from M model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with M model reaction IDs as keys and lists of corresponding ME reaction IDs as values\n",
    "    \"\"\"\n",
    "    m_to_me = {}\n",
    "    \n",
    "    # For each M model reaction, find corresponding ME reactions\n",
    "    for m_rxn in m_model.reactions:\n",
    "        # Find all ME reactions that contain this M reaction ID\n",
    "        me_rxns = [me_rxn.id for me_rxn in me_model.reactions \n",
    "                  if m_rxn.id in me_rxn.id]\n",
    "        \n",
    "        if me_rxns:\n",
    "            m_to_me[m_rxn.id] = me_rxns\n",
    "            \n",
    "    return m_to_me\n",
    "\n",
    "# build pathway reference using other models\n",
    "files = []\n",
    "for f in os.listdir(os.path.join(coralme_dir, 'data', 'external', 'pathways')):\n",
    "    path = os.path.join(coralme_dir, 'data', 'external', 'pathways', f)\n",
    "    files.append(path)\n",
    "files.sort()\n",
    "models_source_df = pd.read_excel(files[0], index_col = 0)\n",
    "models_source_df['source'] = 'iML1515'\n",
    "for f in files[1:]:\n",
    "    df = pd.read_excel(f, index_col = 0)\n",
    "    df['source'] = f.split('pathways/')[1][2:-4]\n",
    "    new = set(df.index) - set(models_source_df.index)\n",
    "    models_source_df = pd.concat([models_source_df, df.loc[list(new)]])\n",
    "\n",
    "# build pathway reference using Carlos mapping\n",
    "models_carlos_df = pd.read_csv(os.path.join(coralme_dir, 'data', 'external', 'geneIDsMapping_PA14_vs_Strains_SubsystemInfo.csv'), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700238dd-3739-4d92-bba9-c407df03ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input files for later\n",
    "\n",
    "# look for default starting media and annotate pathways\n",
    "if False: # this is no longer necessary\n",
    "    path = os.path.join(coralme_dir, 'data', 'default_model_exchanges.pkl')\n",
    "    if os.path.exists(path):\n",
    "        pickle_in = open(path, 'rb')\n",
    "        default_exchanges = pickle.load(pickle_in)\n",
    "        pickle_in.close()\n",
    "    else:\n",
    "        default_exchanges = {}\n",
    "\n",
    "# create EC to pathway mapping\n",
    "resp = requests.get('https://rest.kegg.jp/link/ec/pathway')\n",
    "EC_to_pathways = {}\n",
    "for line in resp.text.split('\\n')[:-1]:\n",
    "    if 'path:ec' in line: continue\n",
    "    ec = line.split('\\t')[1][3:]\n",
    "    path = line.split('\\t')[0][5:]\n",
    "    if ec not in EC_to_pathways:\n",
    "        EC_to_pathways.update({ec : set()})\n",
    "    EC_to_pathways[ec].add(path)\n",
    "\n",
    "# now create mapping from pathway to name\n",
    "resp = requests.get('https://rest.kegg.jp/list/pathway')\n",
    "pathway_to_name = {}\n",
    "for line in resp.text.split('\\n')[:-1]:\n",
    "    pathway_to_name.update({line.split('\\t')[0] : line.split('\\t')[1]})\n",
    "\n",
    "# loop through each model\n",
    "spec_to_neg_EX = {}\n",
    "base_dir = os.path.join(coralme_dir, 'species_files', 'Pseudomonas_files')\n",
    "for f in os.listdir(os.path.join(base_dir, 'individual_species')):\n",
    "    if f == 'Reference': continue\n",
    "        \n",
    "    # load in ME_model\n",
    "    out_path = os.path.join(base_dir, 'individual_species', f, 'outputs')\n",
    "    if not force_rerun and os.path.exists(os.path.join(out_path, 'pathway_annotated_model.pkl')):\n",
    "        print(str(f)+' : pathway annotated model already created, skipping')\n",
    "        continue\n",
    "    out_dict = {}\n",
    "    opts = os.listdir(out_path)\n",
    "    model_name = None\n",
    "    for opt in opts:\n",
    "        if 'step3' in opt:\n",
    "            model_name = opt\n",
    "    if not model_name:\n",
    "        print(str(f)+' : model doesn\\'t exist')\n",
    "        continue\n",
    "    print(str(f)+' : loading model...', end = '')\n",
    "    ME_model = coralme.io.pickle.load_pickle_me_model(os.path.join(out_path, model_name))\n",
    "    model_path = os.path.join(base_dir, 'individual_species', f, 'inputs', 'model.json')\n",
    "    M_model = cobra.io.load_json_model(model_path)\n",
    "    \n",
    "    # look through exchange reactions to figure out what the media type is\n",
    "    print('finding media exchanges...', end = '')\n",
    "    spec_to_neg_EX.update({f : set()})\n",
    "    for rxn in ME_model.reactions:\n",
    "        if 'EX_' not in rxn.id:\n",
    "            continue\n",
    "        elif rxn.lower_bound < 0:\n",
    "            spec_to_neg_EX[f].add((rxn.id, rxn.lower_bound, rxn.upper_bound))\n",
    "\n",
    "    # let's also create subsystem annotations in the ME model\n",
    "    print('mapping pathways...', end = '')\n",
    "    mapping = create_m_to_me_mapping(M_model, ME_model)\n",
    "    mapping_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_to_ME_mapping.pkl')\n",
    "    pickle_out = open(mapping_path, 'wb')\n",
    "    pickle.dump(mapping, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    for M_rxn, ME_rxns in mapping.items():\n",
    "        if 'ec-code' not in M_model.reactions.get_by_id(M_rxn).annotation: continue\n",
    "        pathways = set()\n",
    "        for ec_code in M_model.reactions.get_by_id(M_rxn).annotation['ec-code']:\n",
    "            if ec_code not in EC_to_pathways: continue\n",
    "            pathways = pathways.union(EC_to_pathways[ec_code])\n",
    "        pathways = list(pathways)\n",
    "        pathways.sort()\n",
    "        for rxn in ME_rxns:\n",
    "            ME_model.reactions.get_by_id(rxn).annotation.update({'EC_id_pathways' : pathways})\n",
    "\n",
    "    # let's also create subsystem annotations in the ME model using the reference organisms\n",
    "    for M_rxn, ME_rxns in mapping.items():\n",
    "        if M_rxn not in models_source_df.index: continue\n",
    "        sub = models_source_df.loc[M_rxn].Subsystem\n",
    "        source = models_source_df.loc[M_rxn].source \n",
    "        for ME_rxn in ME_rxns:\n",
    "            ME_rxn = ME_model.reactions.get_by_id(ME_rxn)\n",
    "            ME_rxn.annotation.update({'ref_pathways' : sub})\n",
    "            ME_rxn.annotation.update({'ref_pathways_source' : source})\n",
    "    \n",
    "    # let's also pass along the GPR rules and add Carlos gene mapping for subsystems\n",
    "    for M_rxn, ME_rxns in mapping.items():\n",
    "        M_rxn = M_model.reactions.get_by_id(M_rxn)\n",
    "        for ME_rxn in ME_rxns:\n",
    "            ME_model.reactions.get_by_id(ME_rxn).annotation.update({'genes' : set(M_rxn.gpr.genes)})\n",
    "            subs = set()\n",
    "            for gene in M_rxn.gpr.genes:\n",
    "                check = models_carlos_df[models_carlos_df[f] == gene]\n",
    "                if len(check) == 0: continue\n",
    "                sub = check.Subsystem.values[0]\n",
    "                subs.add(sub)\n",
    "            subs = list(subs)\n",
    "            subs.sort()\n",
    "            ME_model.reactions.get_by_id(ME_rxn).annotation.update({'carlos_pathways' : subs})\n",
    "        \n",
    "    # now let's save the ME model with the annotations\n",
    "    print('saving model...', end = '')\n",
    "    coralme.io.pickle.save_pickle_me_model(ME_model, os.path.join(out_path, 'pathway_annotated_model.pkl'))\n",
    "    print(' done!')\n",
    "    if run_once:\n",
    "        break\n",
    "\n",
    "if False:\n",
    "    # save off changes\n",
    "    pickle_out = open(path, 'wb')\n",
    "    pickle.dump(default_exchanges, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961df80d-6869-4edb-be43-9ed80ce6023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for solutions, run if nonexistant\n",
    "base_dir = os.path.join(coralme_dir, 'species_files', 'Pseudomonas_files')\n",
    "for f in os.listdir(os.path.join(base_dir, 'individual_species')):\n",
    "    if 'Reference' in f: continue\n",
    "    \n",
    "    # look to see if solution already exists\n",
    "    sol_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_solution.pkl')\n",
    "    M_sol_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_flux_solution.pkl')\n",
    "    M_flux_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_flux_ref_solution_dict.pkl')\n",
    "    flux_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_EC_solution_dict.pkl')\n",
    "    flux_path2 = os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_ref_solution_dict.pkl')\n",
    "    out_path = os.path.join(base_dir, 'individual_species', f, 'outputs')\n",
    "    if False: # zzz not force_rerun and os.path.exists(sol_path) and os.path.exists(M_sol_path) and os.path.exists(flux_path) and os.path.exists(flux_path2):\n",
    "        print(str(f)+' : already run')\n",
    "        continue\n",
    "    if not os.path.exists(os.path.join(out_path, 'pathway_annotated_model.pkl')):\n",
    "        print(str(f)+' : pathway annotated model does not exist, skipping')\n",
    "        continue\n",
    "    print(str(f)+' : working...', end = '')\n",
    "    \n",
    "    # run M model simulations\n",
    "    M_model_path = os.path.join(base_dir, 'individual_species', f, 'inputs', 'model.json')\n",
    "    M_v2_model_path = os.path.join(base_dir, 'individual_species', f, 'inputs', 'M_as_ME_for_QMINOS_model.json')\n",
    "    if True: # zzz force_rerun or not os.path.exists(M_sol_path):\n",
    "        print('running M model...', end = '')\n",
    "        if True:#not os.path.exists(M_v2_model_path): # zzz xxx todo\n",
    "            # let's make the model\n",
    "            temp_M_model = cobra.io.load_json_model(M_model_path)\n",
    "            M_as_ME_model = coralme.core.old_model.MEModel.from_cobra(temp_M_model)\n",
    "            M_as_ME_model.global_info.update({\n",
    "                'kt': 4.5,  # This was k_t in your default_parameters\n",
    "                'r0': 0.087,\n",
    "                'k_deg': 12.0,  # This was k^mRNA_deg in your default_parameters\n",
    "                'm_rr': 1453.0,\n",
    "                'm_aa': 0.109,\n",
    "                'f_rRNA': 0.86,\n",
    "                'm_nt': 0.324,\n",
    "                'f_mRNA': 0.02,\n",
    "                'm_tRNA': 25.0,\n",
    "                'f_tRNA': 0.12\n",
    "            })\n",
    "            coralme.io.json.save_json_me_model(M_as_ME_model, M_v2_model_path)\n",
    "        else:\n",
    "            M_model = coralme.io.json.load_json_me_model(M_v2_model_path)\n",
    "\n",
    "        # run on this default medium\n",
    "        solution = M_model.optimize(max_mu = 0.5, min_mu = 0.01, tolerance = 1e-4, maxIter = 20)\n",
    "    \n",
    "        # if there is a solution, create pathway to flux and annotation, save them\n",
    "        if solution:\n",
    "            print('saving solution...', end = '')\n",
    "            rxns = []\n",
    "            fluxes = []\n",
    "            pathways = []\n",
    "            for rxn, flux in M_model.solution.fluxes.items():\n",
    "                M_rxn = M_model.reactions.get_by_id(rxn)\n",
    "                if 'ref_pathways' in M_rxn.annotation:\n",
    "                    rxns.append(rxn)\n",
    "                    fluxes.append(flux)\n",
    "                    pathways.append(M_rxn.annotation['ref_pathways'])\n",
    "            flux_df = pd.DataFrame(index = rxns)\n",
    "            flux_df['flux'] = fluxes\n",
    "            flux_df['pathways'] = pathways\n",
    "            flux_df.to_pickle(M_flux_path)\n",
    "        \n",
    "            # save off solution\n",
    "            pickle_out = open(M_sol_path, 'wb')\n",
    "            pickle.dump(ME_model.solution, pickle_out)\n",
    "            pickle_out.close()\n",
    "        else:\n",
    "            print('no solution...', end = '')\n",
    "            # save something bogus to prevent rerunning this\n",
    "            pickle_out = open(M_flux_path, 'wb')\n",
    "            pickle.dump(False, pickle_out)\n",
    "            pickle_out.close()\n",
    "            \n",
    "            # save off solution\n",
    "            pickle_out = open(M_sol_path, 'wb')\n",
    "            pickle.dump(False, pickle_out)\n",
    "            pickle_out.close()\n",
    "    \n",
    "    # run ME model simulations if it doesn't exist\n",
    "    if force_rerun or not os.path.exists(sol_path):\n",
    "        print('running ME model...', end = '')\n",
    "        ME_model = coralme.io.pickle.load_pickle_me_model(os.path.join(out_path, 'pathway_annotated_model.pkl'))\n",
    "        \n",
    "        # run on this default medium\n",
    "        solution = ME_model.optimize(max_mu = 0.5, min_mu = 0.01, tolerance = 1e-4, maxIter = 20)\n",
    "    \n",
    "        # if there is a solution, create pathway to flux and annotation, save them\n",
    "        if solution:\n",
    "            print('saving solution...', end = '')\n",
    "            rxns = []\n",
    "            fluxes = []\n",
    "            pathways = []\n",
    "            rxns2 = []\n",
    "            fluxes2 = []\n",
    "            pathways2 = []\n",
    "            for rxn, flux in ME_model.solution.fluxes.items():\n",
    "                ME_rxn = ME_model.reactions.get_by_id(rxn)\n",
    "                if 'EC_id_pathways' in ME_rxn.annotation:\n",
    "                    rxns.append(rxn)\n",
    "                    fluxes.append(flux)\n",
    "                    pathways.append(ME_rxn.annotation['EC_id_pathways'])\n",
    "                if 'ref_pathways' in ME_rxn.annotation:\n",
    "                    rxns2.append(rxn)\n",
    "                    fluxes2.append(flux)\n",
    "                    pathways2.append(ME_rxn.annotation['ref_pathways'])\n",
    "            flux_df = pd.DataFrame(index = rxns)\n",
    "            flux_df['flux'] = fluxes\n",
    "            flux_df['pathways'] = pathways\n",
    "            flux_df.to_pickle(flux_path)\n",
    "            flux_df2 = pd.DataFrame(index = rxns2)\n",
    "            flux_df2['flux'] = fluxes2\n",
    "            flux_df2['pathways'] = pathways2\n",
    "            flux_df2.to_pickle(flux_path2)\n",
    "        \n",
    "            # save off solution\n",
    "            pickle_out = open(sol_path, 'wb')\n",
    "            pickle.dump(ME_model.solution, pickle_out)\n",
    "            pickle_out.close()\n",
    "        else:\n",
    "            print('no solution...', end = '')\n",
    "            # save something bogus to prevent rerunning this\n",
    "            pickle_out = open(flux_path, 'wb')\n",
    "            pickle.dump(False, pickle_out)\n",
    "            pickle_out.close()\n",
    "            pickle_out = open(flux_path2, 'wb')\n",
    "            pickle.dump(False, pickle_out)\n",
    "            pickle_out.close()\n",
    "            \n",
    "            # save off solution\n",
    "            pickle_out = open(sol_path, 'wb')\n",
    "            pickle.dump(False, pickle_out)\n",
    "            pickle_out.close()\n",
    "    print(' done!')\n",
    "    if run_once:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86eeab-4cf2-4d67-a33b-dc10469d9ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(coralme.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be1c32-da10-488f-b673-7b0b9faf9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_as_ME_model.global_info.update({\n",
    "    'kt': 4.5,  # This was k_t in your default_parameters\n",
    "    'r0': 0.087,\n",
    "    'k_deg': 12.0,  # This was k^mRNA_deg in your default_parameters\n",
    "    'm_rr': 1453.0,\n",
    "    'm_aa': 0.109,\n",
    "    'f_rRNA': 0.86,\n",
    "    'm_nt': 0.324,\n",
    "    'f_mRNA': 0.02,\n",
    "    'm_tRNA': 25.0,\n",
    "    'f_tRNA': 0.12\n",
    "})\n",
    "coralme.io.json.save_json_me_model(M_as_ME_model, M_v2_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec90af0-735f-4714-9918-31e0d63d8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "opts = list(set(models_carlos_df.Subsystem))\n",
    "\n",
    "# let's loop through all of these to pull out flux_dfs\n",
    "base_dir = os.path.join(coralme_dir, 'species_files', 'Pseudomonas_files')\n",
    "plt_df = pd.DataFrame(index = opts)\n",
    "total_df = pd.DataFrame(index = opts)\n",
    "for f in os.listdir(os.path.join(base_dir, 'individual_species')):\n",
    "    if 'Reference' in f: continue\n",
    "    \n",
    "    # look to see if solution already exists\n",
    "    M_sol_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_flux_solution.pkl')\n",
    "    M_flux_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_flux_ref_solution_dict.pkl')\n",
    "    ME_sol_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_solution.pkl')\n",
    "    ME_flux_path= os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_ref_solution_dict.pkl')\n",
    "    tot_paths = [M_sol_path, M_flux_path, ME_sol_path, ME_flux_path]\n",
    "    if not all([os.path.exists(path) for path in tot_paths]):# not os.path.exists(sol_path) or not os.path.exists(M_sol_path) or not os.path.exists(flux_path) or not os.path.exists(flux_path2):\n",
    "        print(str(f)+' : not yet run')\n",
    "        continue\n",
    "    \n",
    "    # load in results\n",
    "    pickle_in = open(M_sol_path, 'rb')\n",
    "    M_sol = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    pickle_in = open(M_flux_path, 'rb')\n",
    "    M_flux_df = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    pickle_in = open(ME_sol_path, 'rb')\n",
    "    ME_sol = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    pickle_in = open(ME_flux_path, 'rb')\n",
    "    ME_flux_df = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    mapping_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_to_ME_mapping.pkl')\n",
    "    pickle_in = open(mapping_path, 'rb')\n",
    "    M_to_ME = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "\n",
    "    # check if solutions exist\n",
    "    if not ME_sol or not M_sol:\n",
    "        print(str(f)+' : no solution, skipping')\n",
    "        continue\n",
    "    \n",
    "    # create combined Dataframe standardized by growth rates\n",
    "    rxns = []\n",
    "    M_fluxes = []\n",
    "    ME_sum_fluxes = []\n",
    "    ME_abs_sum_fluxes = []\n",
    "    pathways = []\n",
    "    for M_rxn, ME_rxns in M_to_ME.items():\n",
    "        if not all([rxn in ME_flux_df.index for rxn in ME_rxns]):\n",
    "            continue\n",
    "        overlap = [rxn for rxn in ME_rxns if rxn in ME_flux_df.index]\n",
    "        M_flux = M_flux_df.loc[M_rxn]['flux'] / M_sol.objective_value\n",
    "        ME_flux = ME_flux_df.loc[overlap]['flux'] / ME_sol.objective_value\n",
    "        for pathway in M_flux_df.loc[M_rxn]['pathways']:\n",
    "            rxns.append(M_rxn)\n",
    "            M_fluxes.append(M_flux)\n",
    "            ME_sum_fluxes.append(sum(ME_flux.values))\n",
    "            ME_abs_sum_fluxes.append(sum(abs(ME_flux.values)))\n",
    "            pathways.append(pathway)\n",
    "    summed_df = pd.DataFrame(index = rxns)\n",
    "    summed_df['M_fluxes'] = M_fluxes\n",
    "    summed_df['sum_abs_ME_fluxes'] = ME_abs_sum_fluxes\n",
    "    summed_df['sum_ME_fluxes'] = ME_sum_fluxes\n",
    "    summed_df['pathways'] = pathways\n",
    "\n",
    "    # now convert to pathway summed flux for plotting\n",
    "    # copying from https://www.nature.com/articles/s41467-020-17612-8\n",
    "    groups = []\n",
    "    M_scores = []\n",
    "    ME_scores = []\n",
    "    for group, df in summed_df.groupby('pathways'):\n",
    "        if sum(abs(df['M_fluxes'])) == 0:\n",
    "            M_score = 0\n",
    "        else:\n",
    "            M_score = sum(df['M_fluxes']) / sum(abs(df['M_fluxes']))\n",
    "        if sum(df['sum_abs_ME_fluxes']) == 0:\n",
    "            ME_score = 0\n",
    "        else:\n",
    "            ME_score = sum(df['sum_ME_fluxes']) / sum(df['sum_abs_ME_fluxes'])\n",
    "        groups.append(group)\n",
    "        M_scores.append(M_score)\n",
    "        ME_scores.append(ME_score)\n",
    "    plot_df = pd.DataFrame(index = groups)\n",
    "    plot_df['M_score'] = M_scores\n",
    "    plot_df['ME_score'] = ME_scores\n",
    "    plot_df[f] = plot_df['ME_score'] - plot_df['M_score']\n",
    "    plt_df = plt_df.join(plot_df[f], how='left')\n",
    "    total_df = total_df.join(plot_df.rename(columns = {'M_score' : 'M_'+f, 'ME_score' : 'ME_'+f}), how = 'left')\n",
    "\n",
    "    ################################################\n",
    "    # individual plot #\n",
    "    ################################################\n",
    "    diff_groups = plot_df.index[plot_df['M_score'] != plot_df['ME_score']]\n",
    "    show_df = plot_df.loc[diff_groups]\n",
    "    x_vals = [i for i in range(len(show_df.index))]\n",
    "    plt.scatter(x_vals, show_df['M_score'], c = 'red', label = 'M model')\n",
    "    plt.scatter(x_vals, show_df['ME_score'], c = 'blue', label = 'ME model')\n",
    "    plt.xticks(np.arange(0, max(x_vals)+1), show_df.index, rotation = 90)\n",
    "    plt.xlabel('Pathways')\n",
    "    plt.ylabel('Flux by Pathway (mmol/gDW/h)')\n",
    "    plt.title('Strain: '+f)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    plt.savefig('../figures/strain_figures/'+f+'_flux_figure.pdf', transparent = True, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "total_df.to_csv('../data/summed_flux_df.csv')\n",
    "\n",
    "################################################\n",
    "# overall plot #\n",
    "################################################\n",
    "plt_df = plt_df.dropna(0, how = 'all').fillna(0)\n",
    "keep = [any([val not in [-1, 0, 1] for val in vals]) for vals in plt_df.values] # remove samples that contain only -1s, 0s, and 1s\n",
    "plt_df = plt_df.loc[keep].sort_index()\n",
    "\n",
    "colors = get_n_colors_from_colormap(len(plt_df.columns), 'plasma')\n",
    "col_to_colors = {col : color for col, color in zip(plt_df.columns, colors)}\n",
    "colors = []\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "labels = []\n",
    "labels_long = []\n",
    "i = 0\n",
    "for index in plt_df.index:\n",
    "    labels.append(index)\n",
    "    for col in plt_df.columns:\n",
    "        val = plt_df.loc[index][col]\n",
    "        x_vals.append(i)\n",
    "        y_vals.append(val)\n",
    "        labels_long.append(col)\n",
    "        colors.append(col_to_colors[col])\n",
    "    i += 1\n",
    "fig, ax = plt.subplots()\n",
    "sorted_x = list(set(x_vals))\n",
    "sorted_x.sort()\n",
    "for x in sorted_x:\n",
    "    plt.axvline(x = x, c = 'grey', alpha = 0.2)\n",
    "plt.scatter(x_vals, y_vals, c = colors)\n",
    "plt.xticks(np.arange(0, max(x_vals)+1), labels, rotation = 90)\n",
    "plt.xlabel('Pathways')\n",
    "plt.ylabel('ME - M Model Flux by Pathway (mmol/gDW/h)')\n",
    "\n",
    "# label the \"outliers\"\n",
    "x_labs = []\n",
    "y_labs = []\n",
    "labs = []\n",
    "for x_val, y_val, lab_temp in zip(x_vals, y_vals, labels_long):\n",
    "    if abs(y_val) > 0.05:\n",
    "        x_labs.append(x_val)\n",
    "        y_labs.append(y_val)\n",
    "        labs.append(lab_temp)\n",
    "if len(labs) < 50:\n",
    "    texts = [ax.text(x_labs[i], y_labs[i], labs[i], ha='center', va='center') for i in range(len(x_labs))]\n",
    "    _ = adjust_text(texts, expand=(1.2, 1.2), # expand text bounding boxes by 1.2 fold in x direction and 2 fold in y direction\n",
    "                arrowprops=dict(arrowstyle='->', color='k')); # ensure the labeling is clear by adding arrows);\n",
    "\n",
    "# Custom legend using patches\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in col_to_colors.items()]\n",
    "plt.legend(handles=legend_patches, title='Species', loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.savefig(os.path.join(coralme_dir, 'figures', 'pathway_flux.pdf'), transparent = True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# most commonly outlier\n",
    "print('How often labelled:')\n",
    "label_to_ct = dict(Counter(labs))\n",
    "sorted_labels = [k for k, _ in sorted(label_to_ct.items(), key = lambda k : -k[1])]\n",
    "for k in sorted_labels:\n",
    "    print(str(k)+' : '+str(label_to_ct[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1f050-cfa2-4c6a-8435-23494d31e977",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37e1bf-5cf8-4ddc-9792-037e67d9de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "use_flux = 1\n",
    "pathways_df = pd.DataFrame(index = pathway_to_name.keys())\n",
    "\n",
    "# let's loop through all of these to pull out flux_dfs\n",
    "base_dir = os.path.join(coralme_dir, 'species_files', 'Pseudomonas_files')\n",
    "for f in os.listdir(os.path.join(base_dir, 'individual_species')):\n",
    "    if 'Reference' in f: continue\n",
    "    \n",
    "    # look to see if solution already exists\n",
    "    sol_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_solution.pkl')\n",
    "    M_sol_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_flux_solution.pkl')\n",
    "    M_flux_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'M_flux_ref_solution_dict.pkl')\n",
    "    flux_path = os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_EC_solution_dict.pkl')\n",
    "    flux_path2 = os.path.join(base_dir, 'individual_species', f, 'outputs', 'flux_ref_solution_dict.pkl')\n",
    "    tot_paths = [sol_path, M_sol_path, M_flux_path, flux_path, flux_path2]\n",
    "    if not all([os.path.exists(path) for path in tot_paths]):# not os.path.exists(sol_path) or not os.path.exists(M_sol_path) or not os.path.exists(flux_path) or not os.path.exists(flux_path2):\n",
    "        print(str(f)+' : not yet run')\n",
    "        continue\n",
    "    \n",
    "    # load in results\n",
    "    pickle_in = open(sol_path, 'rb')\n",
    "    sol = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    pickle_in = open(flux_path, 'rb')\n",
    "    flux_df = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    pickle_in = open(flux_path2, 'rb')\n",
    "    flux_df2 = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    if type(flux_df) == bool or len(flux_df) == 0:\n",
    "        continue\n",
    "    \n",
    "    # reorganize by pathway groups\n",
    "    pathway_to_fluxes = {}\n",
    "    if use_flux == 1:\n",
    "        for index, row in flux_df.iterrows():\n",
    "            pathways = row['pathways']\n",
    "            if str(pathways) == 'nan': continue\n",
    "            for pathway in pathways:\n",
    "                if pathway not in pathway_to_fluxes:\n",
    "                    pathway_to_fluxes.update({pathway : []})\n",
    "                pathway_to_fluxes[pathway].append(row['flux'])\n",
    "    else:\n",
    "        for index, row in flux_df2.iterrows():\n",
    "            pathway = row['pathways']\n",
    "            if str(pathways) == 'nan': continue\n",
    "            if pathway not in pathway_to_fluxes:\n",
    "                pathway_to_fluxes.update({pathway : []})\n",
    "            pathway_to_fluxes[pathway].append(row['flux'])\n",
    "    \n",
    "    # take max of each to represent the flux through the map (not sure what the best strategy is, maybe manually pick bottlenecks?)\n",
    "    vals = []\n",
    "    for pathway in pathways_df.index:\n",
    "        if pathway in pathway_to_fluxes:\n",
    "            # copying from https://www.nature.com/articles/s41467-020-17612-8\n",
    "            total = sum(pathway_to_fluxes[pathway])\n",
    "            abs_total = sum([abs(val) for val in pathway_to_fluxes[pathway]])\n",
    "            if abs_total == 0:\n",
    "                vals.append(0)\n",
    "            else:\n",
    "                vals.append(total / abs_total)\n",
    "        else:\n",
    "            vals.append(None)\n",
    "    pathways_df[f] = vals\n",
    "\n",
    "# now we can plot\n",
    "pathways_df = pathways_df.rename(pathway_to_name).sort_index(key = lambda ind : ind.str.lower())\n",
    "pathways_df = pathways_df.dropna(0, how = 'all')\n",
    "keep = pathways_df.index[abs(pathways_df).sum(axis = 1) != 0] # remove examples where all zero\n",
    "pathways_df = pathways_df.loc[keep]\n",
    "keep = pathways_df.index[abs(pathways_df).sum(axis = 1) != len(pathways_df.columns)] # remove examples of all 1s or all -1s\n",
    "pathways_df = pathways_df.loc[keep]\n",
    "keep = [any([val not in [-1, 0, 1] for val in vals]) for vals in pathways_df.values] # remove samples that contain only -1s, 0s, and 1s\n",
    "pathways_df = pathways_df.loc[keep]\n",
    "\n",
    "colors = get_n_colors_from_colormap(len(pathways_df.columns), 'plasma')\n",
    "col_to_colors = {col : color for col, color in zip(pathways_df.columns, colors)}\n",
    "colors = []\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "labels = []\n",
    "labels_long = []\n",
    "i = 0\n",
    "for index in pathways_df.index:\n",
    "    labels.append(index)\n",
    "    for col in pathways_df.columns:\n",
    "        val = pathways_df.loc[index][col]\n",
    "        x_vals.append(i)\n",
    "        y_vals.append(val)\n",
    "        labels_long.append(col)\n",
    "        colors.append(col_to_colors[col])\n",
    "    i += 1\n",
    "fig, ax = plt.subplots()\n",
    "sorted_x = list(set(x_vals))\n",
    "sorted_x.sort()\n",
    "for x in sorted_x:\n",
    "    plt.axvline(x = x, c = 'grey', alpha = 0.2)\n",
    "plt.scatter(x_vals, y_vals, c = colors)\n",
    "plt.xticks(np.arange(0, max(x_vals)+1), labels, rotation = 90)\n",
    "plt.xlabel('Pathways')\n",
    "plt.ylabel('Flux by Pathway (mmol/gDW/h)')\n",
    "\n",
    "# label the \"outliers\"\n",
    "x_labs = []\n",
    "y_labs = []\n",
    "labs = []\n",
    "for x_val, y_val, lab_temp in zip(x_vals, y_vals, labels_long):\n",
    "    if abs(y_val) < 0.95 and abs(y_val) > 0.05:\n",
    "        x_labs.append(x_val)\n",
    "        y_labs.append(y_val)\n",
    "        labs.append(lab_temp)\n",
    "texts = [ax.text(x_labs[i], y_labs[i], labs[i], ha='center', va='center') for i in range(len(x_labs))]\n",
    "_ = adjust_text(texts, expand=(1.2, 1.2), # expand text bounding boxes by 1.2 fold in x direction and 2 fold in y direction\n",
    "            arrowprops=dict(arrowstyle='->', color='k')); # ensure the labeling is clear by adding arrows);\n",
    "\n",
    "# Custom legend using patches\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in col_to_colors.items()]\n",
    "plt.legend(handles=legend_patches, title='Species', loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.savefig(os.path.join(coralme_dir, 'figures', 'pathway_flux.pdf'), transparent = True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# most commonly outlier\n",
    "print('How often labelled:')\n",
    "label_to_ct = dict(Counter(labs))\n",
    "sorted_labels = [k for k, _ in sorted(label_to_ct.items(), key = lambda k : -k[1])]\n",
    "for k in sorted_labels:\n",
    "    print(str(k)+' : '+str(label_to_ct[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985711ef-971f-4fe5-b4a5-e04e676bfe00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
